# -*- coding: utf-8 -*-
"""Copy of Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_CZYxakNarqVUvrAJtyczlaCoI1RoDKg
"""

import gradio as gr
import io
import re
import base64
from typing import List, Tuple, Optional
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import warnings
warnings.filterwarnings("ignore")

# Try to import PDF processing library
try:
    import fitz  # PyMuPDF
    PDF_PROCESSOR = "pymupdf"
except ImportError:
    try:
        import PyPDF2
        PDF_PROCESSOR = "pypdf2"
    except ImportError:
        PDF_PROCESSOR = None

class StudyMateAI:
    def __init__(self):
        """Initialize the StudyMate AI system with IBM Granite model."""
        self.tokenizer = None
        self.model = None
        self.pdf_content = ""
        self.load_model()

    def load_model(self):
        """Load the IBM Granite model."""
        try:
            print("Loading IBM Granite model...")
            self.tokenizer = AutoTokenizer.from_pretrained("ibm-granite/granite-3.3-2b-instruct")
            self.model = AutoModelForCausalLM.from_pretrained("ibm-granite/granite-3.3-2b-instruct")

            # Move to GPU if available
            if torch.cuda.is_available():
                self.model = self.model.cuda()
                print("Model loaded on GPU")
            else:
                print("Model loaded on CPU")

        except Exception as e:
            print(f"Error loading model: {e}")
            raise e

    def extract_text_from_pdf(self, pdf_file) -> str:
        """Extract text content from uploaded PDF file."""
        if pdf_file is None:
            return ""

        if PDF_PROCESSOR is None:
            return "Error: No PDF processing library available. Please install either 'pip install PyMuPDF' or 'pip install PyPDF2'"

        try:
            pdf_content = ""

            if PDF_PROCESSOR == "pymupdf":
                # Using PyMuPDF (fitz)
                pdf_document = fitz.open(pdf_file)
                for page_num in range(len(pdf_document)):
                    page = pdf_document.load_page(page_num)
                    text = page.get_text()
                    if text and text.strip():
                        pdf_content += f"\n--- Page {page_num + 1} ---\n{text}\n"
                pdf_document.close()

            elif PDF_PROCESSOR == "pypdf2":
                # Using PyPDF2
                with open(pdf_file, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    for page_num, page in enumerate(pdf_reader.pages):
                        text = page.extract_text()
                        if text and text.strip():
                            pdf_content += f"\n--- Page {page_num + 1} ---\n{text}\n"

            # Clean up the text
            pdf_content = re.sub(r'\n+', '\n', pdf_content)
            pdf_content = re.sub(r'\s+', ' ', pdf_content)

            return pdf_content.strip()

        except Exception as e:
            return f"Error reading PDF: {str(e)}"

    def generate_response(self, prompt: str, max_tokens: int = 512) -> str:
        """Generate response using IBM Granite model."""
        try:
            messages = [
                {"role": "user", "content": prompt}
            ]

            inputs = self.tokenizer.apply_chat_template(
                messages,
                add_generation_prompt=True,
                tokenize=True,
                return_dict=True,
                return_tensors="pt",
            ).to(self.model.device)

            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_tokens,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )

            response = self.tokenizer.decode(
                outputs[0][inputs["input_ids"].shape[-1]:],
                skip_special_tokens=True
            )

            return response.strip()

        except Exception as e:
            return f"Error generating response: {str(e)}"

    def process_pdf_upload(self, pdf_file) -> str:
        """Process uploaded PDF and return status."""
        if pdf_file is None:
            return "‚ùå No PDF file uploaded. Please upload a PDF file first."

        self.pdf_content = self.extract_text_from_pdf(pdf_file)

        if not self.pdf_content or "Error reading PDF" in self.pdf_content:
            return f"‚ùå Failed to process PDF: {self.pdf_content}"

        word_count = len(self.pdf_content.split())
        return f"‚úÖ PDF processed successfully!\nüìÑ Document contains {word_count} words and is ready for Q&A."

    def answer_question(self, question: str) -> str:
        """Answer a question based on the uploaded PDF content."""
        if not self.pdf_content:
            return "‚ùå Please upload and process a PDF file first."

        if not question.strip():
            return "‚ùå Please enter a question."

        # Create a focused prompt for Q&A
        prompt = f"""Based on the following document content, please answer the question accurately and concisely.

Document Content:
{self.pdf_content[:3000]}...

Question: {question}

Instructions:
- Provide a clear, direct answer based only on the document content
- If the answer is not in the document, say so clearly
- Quote relevant parts when helpful
- Keep the response concise but complete

Answer:"""

        response = self.generate_response(prompt, max_tokens=400)
        return response

    def generate_qa_pairs(self, num_questions: int = 5) -> str:
        """Generate Q&A pairs from the PDF content."""
        if not self.pdf_content:
            return "‚ùå Please upload and process a PDF file first."

        prompt = f"""Based on the following document content, generate {num_questions} important questions and their answers.

Document Content:
{self.pdf_content[:2500]}...

Instructions:
- Create diverse, meaningful questions that test understanding
- Include factual, conceptual, and analytical questions
- Provide clear, accurate answers based on the content
- Format as: Q1: [question] A1: [answer]

Generate {num_questions} Q&A pairs:"""

        response = self.generate_response(prompt, max_tokens=600)
        return response

    def create_study_plan(self, study_duration: str, focus_areas: str) -> str:
        """Create a customized study plan based on PDF content."""
        if not self.pdf_content:
            return "‚ùå Please upload and process a PDF file first."

        # Extract key topics from PDF content
        content_preview = self.pdf_content[:2000]

        prompt = f"""Create a personalized study plan based on the following document content.

Document Content Preview:
{content_preview}...

Study Parameters:
- Duration: {study_duration}
- Focus Areas: {focus_areas if focus_areas else "General overview of all topics"}

Instructions:
- Create a structured study schedule
- Break down topics by priority and difficulty
- Include specific learning objectives
- Suggest review sessions and practice activities
- Make it practical and achievable

Study Plan:"""

        response = self.generate_response(prompt, max_tokens=700)
        return response

# Initialize the StudyMate AI system
studymate = StudyMateAI()

def create_interface():
    """Create the Gradio interface for StudyMate."""

    # Custom CSS for attractive styling
    custom_css = """
    .gradio-container {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .header {
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .feature-box {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    """

    with gr.Blocks(css=custom_css, title="StudyMate - AI Study Assistant") as interface:

        # Header
        gr.HTML("""
        <div class="header">
            <h1>üìö StudyMate</h1>
            <p style="font-size: 1.2em; margin: 0;">AI-Powered PDF-Based Q&A System for Students</p>
            <p style="opacity: 0.9; margin: 0.5rem 0 0 0;">Upload your study materials and get instant answers, practice questions, and personalized study plans!</p>
        </div>
        """)

        # Main interface
        with gr.Row():
            with gr.Column(scale=1):
                gr.HTML('<div class="feature-box"><h3>üìÑ Document Upload</h3></div>')
                pdf_upload = gr.File(
                    label="Upload PDF Document",
                    file_types=[".pdf"],
                    type="filepath"
                )
                process_btn = gr.Button("Process PDF", variant="primary", size="lg")
                pdf_status = gr.Textbox(
                    label="Processing Status",
                    interactive=False,
                    lines=3
                )

            with gr.Column(scale=2):
                gr.HTML('<div class="feature-box"><h3>ü§ñ AI Assistant</h3></div>')

                with gr.Tab("üí¨ Q&A Chat"):
                    question_input = gr.Textbox(
                        label="Ask a Question",
                        placeholder="Enter your question about the uploaded document...",
                        lines=2
                    )
                    ask_btn = gr.Button("Get Answer", variant="secondary")
                    answer_output = gr.Textbox(
                        label="Answer",
                        lines=8,
                        interactive=False
                    )

                with gr.Tab("‚ùì Generate Practice Questions"):
                    num_questions = gr.Slider(
                        minimum=3,
                        maximum=10,
                        value=5,
                        step=1,
                        label="Number of Questions"
                    )
                    generate_qa_btn = gr.Button("Generate Q&A", variant="secondary")
                    qa_output = gr.Textbox(
                        label="Generated Questions & Answers",
                        lines=12,
                        interactive=False
                    )

                with gr.Tab("üìã Study Planner"):
                    with gr.Row():
                        duration = gr.Dropdown(
                            choices=["1 week", "2 weeks", "1 month", "2 months", "1 semester"],
                            value="2 weeks",
                            label="Study Duration"
                        )
                        focus_areas = gr.Textbox(
                            label="Focus Areas (Optional)",
                            placeholder="e.g., chapters 1-3, mathematical concepts, etc.",
                            lines=2
                        )
                    create_plan_btn = gr.Button("Create Study Plan", variant="secondary")
                    plan_output = gr.Textbox(
                        label="Personalized Study Plan",
                        lines=12,
                        interactive=False
                    )

        # Footer
        gr.HTML("""
        <div style="text-align: center; margin-top: 2rem; padding: 1rem; background: #f8f9fa; border-radius: 8px;">
            <p><strong>üí° Tips:</strong> Upload clear, text-based PDFs for best results. The AI works best with academic papers, textbooks, and lecture notes.</p>
            <p><em>Powered by IBM Granite 3.3-2B Model</em></p>
        </div>
        """)

        # Event handlers
        process_btn.click(
            fn=studymate.process_pdf_upload,
            inputs=[pdf_upload],
            outputs=[pdf_status]
        )

        ask_btn.click(
            fn=studymate.answer_question,
            inputs=[question_input],
            outputs=[answer_output]
        )

        question_input.submit(
            fn=studymate.answer_question,
            inputs=[question_input],
            outputs=[answer_output]
        )

        generate_qa_btn.click(
            fn=studymate.generate_qa_pairs,
            inputs=[num_questions],
            outputs=[qa_output]
        )

        create_plan_btn.click(
            fn=studymate.create_study_plan,
            inputs=[duration, focus_areas],
            outputs=[plan_output]
        )

    return interface

if __name__ == "__main__":
    print("üöÄ Starting StudyMate Application...")
    print("üìã Features available:")
    print("   ‚Ä¢ PDF document processing")
    print("   ‚Ä¢ Interactive Q&A with your documents")
    print("   ‚Ä¢ Practice question generation")
    print("   ‚Ä¢ Personalized study plan creation")
    print("\n‚ö° Powered by IBM Granite 3.3-2B Model")

    # Create and launch the interface
    app = create_interface()
    app.launch(
        share=True,
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True
    )